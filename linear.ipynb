{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Линейные методы\n",
    "\n",
    "Набор данных - выбран набор данных с иинформацией о пассажирах Титаника."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67479c2bf7bbed40"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Импорт необходимых библиотек:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fd20fde1d671d5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from build_data import get_processed_data\n",
    "from lin_regression import (\n",
    "    transform_labels as transform_labels_lr,\n",
    "    add_intercept as add_intercept_lr,\n",
    "    ridge_regression,\n",
    "    predict as predict_lr,\n",
    "    evaluate_accuracy as evaluate_accuracy_lr\n",
    ")\n",
    "from lin_classification import (\n",
    "    transform_labels as transform_labels_lc,\n",
    "    add_intercept as add_intercept_lc,\n",
    "    LinearClassifier,\n",
    ")\n",
    "from svm import SVM_SMO\n",
    "\n",
    "best_params_lc = None\n",
    "best_params_svm = None\n",
    "best_lambda_lr = None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43e7c9294c9378af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "При помощи функций из build_data.py у меня происходит:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "474f6b60f2b328d1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Загрузка тренировочного и тестового наборов данных, предобработка данных, разделение тестового набора данных на тренировочную и валидационную выборки, "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfc2de90f80ac88c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_data(train_path, test_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    return train_df, test_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "150787d375551f30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess_data(train_df, test_df):\n",
    "    train_df = train_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "    test_df = test_df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "    imputer_age = SimpleImputer(strategy='median')\n",
    "    train_df['Age'] = imputer_age.fit_transform(train_df[['Age']])\n",
    "    test_df['Age'] = imputer_age.transform(test_df[['Age']])\n",
    "\n",
    "    imputer_embarked = SimpleImputer(strategy='most_frequent')\n",
    "    train_df['Embarked'] = imputer_embarked.fit_transform(train_df[['Embarked']]).ravel()\n",
    "\n",
    "    imputer_fare = SimpleImputer(strategy='median')\n",
    "    test_df['Fare'] = imputer_fare.fit_transform(test_df[['Fare']])\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    train_df['Sex'] = le.fit_transform(train_df['Sex'])\n",
    "    test_df['Sex'] = le.transform(test_df['Sex'])\n",
    "\n",
    "    train_df = pd.get_dummies(train_df, columns=['Embarked'], drop_first=True)\n",
    "    test_df = pd.get_dummies(test_df, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "    missing_cols = set(train_df.columns) - set(test_df.columns)\n",
    "    for col in missing_cols:\n",
    "        if col != 'Survived':\n",
    "            test_df[col] = 0\n",
    "\n",
    "    test_df = test_df[train_df.drop('Survived', axis=1).columns]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    numeric_features = ['Age', 'Fare', 'SibSp', 'Parch', 'Pclass']\n",
    "    train_df[numeric_features] = scaler.fit_transform(train_df[numeric_features])\n",
    "    test_df[numeric_features] = scaler.transform(test_df[numeric_features])\n",
    "\n",
    "    return train_df, test_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51c3630c0a7eea61"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_data(train_df, test_size=0.2, random_state=42):\n",
    "    X = train_df.drop('Survived', axis=1)\n",
    "    y = train_df['Survived']\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    return X_train, X_val, y_train, y_val"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b03ff1ec1a744f30"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Функция, вызов которой в main вызовет правильный процесс загрузки и обработки данных:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1d4b27a25c8a38b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_processed_data(train_path='train.csv', test_path='test.csv'):\n",
    "    train_df, test_df = load_data(train_path, test_path)\n",
    "    train_df, test_df = preprocess_data(train_df, test_df)\n",
    "    X_train, X_val, y_train, y_val = split_data(train_df)\n",
    "    return X_train, X_val, y_train, y_val, test_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70fb352288f72a5e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Алгоритм линейной регрессии с гребневой регуляризацией в матричном виде:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "379b932725b8c11b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def transform_labels(y):\n",
    "    return np.where(y == 1, 1, -1).reshape(-1, 1)\n",
    "\n",
    "def add_intercept(X):\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    return np.hstack((intercept, X))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "773f851f71d5c3be"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Реализация линейной регрессии с гребневой регуляризацией"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "167751525066594d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ridge_regression(X, y, lambda_reg):\n",
    "    n_features = X.shape[1]\n",
    "    I = np.eye(n_features)\n",
    "    I[0, 0] = 0\n",
    "    w = np.linalg.inv(X.T @ X + lambda_reg * I) @ X.T @ y\n",
    "    return w"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b52b0bf36a3f1da1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Прогнозирование и оценка точности модели"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f2ce94604007284"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict(X, w):\n",
    "    return np.sign(X @ w)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99f3794aeb545990"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1997d70e9e6fea3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Алгоритм линейной классификации"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ec712c0754f1448"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def transform_labels(y):\n",
    "    return np.where(y == 1, 1, -1).reshape(-1, 1)\n",
    "\n",
    "def add_intercept(X):\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    return np.hstack((intercept, X))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac202b419f3b56e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LinearClassifier:\n",
    "    def __init__(self, loss='mse', learning_rate=0.01, n_iterations=1000, lambda1=0.0, lambda2=0.0):\n",
    "        self.loss = loss\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.w = None\n",
    "        self.loss_history = []\n",
    "        self.test_loss_history = []\n",
    "        self.test_accuracy_history = []\n",
    "\n",
    "    def loss_and_gradient(self, X, y):\n",
    "        m = X.shape[0]\n",
    "        scores = X @ self.w\n",
    "        margins = y * scores\n",
    "\n",
    "        if self.loss == 'mse':\n",
    "            loss = (1 - margins) ** 2\n",
    "            gradient = -(X.T @ (y * (1 - margins))) / m\n",
    "        elif self.loss == 'logistic':\n",
    "            loss = np.log(1 + np.exp(-margins))\n",
    "            sigmoid = 1 / (1 + np.exp(-margins))\n",
    "            gradient = -(X.T @ (y * (1 - sigmoid))) / m\n",
    "        elif self.loss == 'exponential':\n",
    "            loss = np.exp(-margins)\n",
    "            gradient = -(X.T @ (y * loss)) / m\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported loss function\")\n",
    "\n",
    "        gradient += self.lambda1 * np.sign(self.w) + 2 * self.lambda2 * self.w\n",
    "        loss_mean = np.mean(loss) + self.lambda1 * np.sum(np.abs(self.w)) + self.lambda2 * np.sum(self.w ** 2)\n",
    "        return loss_mean, gradient\n",
    "\n",
    "    def fit(self, X_train, y_train, X_test=None, y_test=None):\n",
    "        m, n = X_train.shape\n",
    "        self.w = np.zeros((n, 1))\n",
    "\n",
    "        for i in range(self.n_iterations):\n",
    "            loss, gradient = self.loss_and_gradient(X_train, y_train)\n",
    "            self.w -= self.learning_rate * gradient\n",
    "            self.loss_history.append(loss)\n",
    "\n",
    "            if X_test is not None and y_test is not None:\n",
    "                test_loss, _ = self.loss_and_gradient(X_test, y_test)\n",
    "                self.test_loss_history.append(test_loss)\n",
    "\n",
    "                y_pred_test = self.predict(X_test)\n",
    "                test_accuracy = self.evaluate_accuracy(y_test, y_pred_test)\n",
    "                self.test_accuracy_history.append(test_accuracy)\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_output = X @ self.w\n",
    "        y_pred = np.sign(linear_output)\n",
    "        y_pred[y_pred == 0] = 1\n",
    "        return y_pred\n",
    "\n",
    "    def evaluate_accuracy(self, y_true, y_pred):\n",
    "        return np.mean(y_true.flatten() == y_pred.flatten())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6db3e47ba3473781"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# svm через smo"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fc81cb784d7e17e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выбраны ядра:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94687dd70014d3d1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def kernel_function(X1, X2, kernel_type='linear', degree=3, gamma=None):\n",
    "    if gamma is None:\n",
    "        gamma = 1 / X1.shape[1]\n",
    "\n",
    "    if kernel_type == 'linear':\n",
    "        return X1 @ X2.T\n",
    "    elif kernel_type == 'polynomial':\n",
    "        return (X1 @ X2.T + 1) ** degree\n",
    "    elif kernel_type == 'rbf':\n",
    "        sq_dists = np.sum(X1 ** 2, axis=1).reshape(-1, 1) + \\\n",
    "                   np.sum(X2 ** 2, axis=1) - 2 * X1 @ X2.T\n",
    "        return np.exp(-gamma * sq_dists)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported kernel type\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29a82eec735f9360"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "20008e0456bb45a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SVM_SMO:\n",
    "    def __init__(self, kernel='linear', C=0.1, tol=1e-3, max_passes=50, degree=3, gamma=None):\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        self.tol = tol\n",
    "        self.max_passes = max_passes\n",
    "        self.degree = degree\n",
    "        self.gamma = gamma\n",
    "        self.alpha = None\n",
    "        self.b = 0\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.K = None\n",
    "        self.f = None\n",
    "        self.loss_history = []\n",
    "        self.test_accuracy_history = []\n",
    "        self.eval_points = []\n",
    "        self.iteration = 0\n",
    "\n",
    "    def fit(self, X, y, X_test=None, y_test=None):\n",
    "        m, n = X.shape\n",
    "        self.X = X.astype(float)\n",
    "        self.y = y.astype(float).reshape(-1, 1)\n",
    "        self.alpha = np.zeros((m, 1))\n",
    "        self.b = 0\n",
    "\n",
    "        self.K = kernel_function(self.X, self.X, kernel_type=self.kernel,\n",
    "                                 degree=self.degree, gamma=self.gamma)\n",
    "\n",
    "        self.f = np.zeros((m, 1))\n",
    "\n",
    "        passes = 0\n",
    "        while passes < self.max_passes:\n",
    "            num_changed_alphas = 0\n",
    "            for i in range(m):\n",
    "                E_i = self.f[i] - self.y[i]\n",
    "\n",
    "                if (self.y[i] * E_i < -self.tol and self.alpha[i] < self.C) or \\\n",
    "                        (self.y[i] * E_i > self.tol and self.alpha[i] > 0):\n",
    "\n",
    "                    j = self._select_j(i, m)\n",
    "                    E_j = self.f[j] - self.y[j]\n",
    "\n",
    "                    alpha_i_old = self.alpha[i].copy()\n",
    "                    alpha_j_old = self.alpha[j].copy()\n",
    "\n",
    "                    if self.y[i] != self.y[j]:\n",
    "                        L = max(0, self.alpha[j] - self.alpha[i])\n",
    "                        H = min(self.C, self.C + self.alpha[j] - self.alpha[i])\n",
    "                    else:\n",
    "                        L = max(0, self.alpha[i] + self.alpha[j] - self.C)\n",
    "                        H = min(self.C, self.alpha[i] + self.alpha[j])\n",
    "                    if L == H:\n",
    "                        continue\n",
    "\n",
    "                    eta = 2.0 * self.K[i, j] - self.K[i, i] - self.K[j, j]\n",
    "                    if eta >= 0:\n",
    "                        continue\n",
    "\n",
    "                    self.alpha[j] -= self.y[j] * (E_i - E_j) / eta\n",
    "                    self.alpha[j] = np.clip(self.alpha[j], L, H)\n",
    "                    if abs(self.alpha[j] - alpha_j_old) < 1e-5:\n",
    "                        continue\n",
    "\n",
    "                    self.alpha[i] += self.y[i] * self.y[j] * (alpha_j_old - self.alpha[j])\n",
    "\n",
    "                    b1 = self.b - E_i - \\\n",
    "                         self.y[i] * (self.alpha[i] - alpha_i_old) * self.K[i, i] - \\\n",
    "                         self.y[j] * (self.alpha[j] - alpha_j_old) * self.K[i, j]\n",
    "                    b2 = self.b - E_j - \\\n",
    "                         self.y[i] * (self.alpha[i] - alpha_i_old) * self.K[i, j] - \\\n",
    "                         self.y[j] * (self.alpha[j] - alpha_j_old) * self.K[j, j]\n",
    "\n",
    "                    if 0 < self.alpha[i] < self.C:\n",
    "                        self.b = b1\n",
    "                    elif 0 < self.alpha[j] < self.C:\n",
    "                        self.b = b2\n",
    "                    else:\n",
    "                        self.b = (b1 + b2) / 2.0\n",
    "\n",
    "                    delta_alpha_i = self.alpha[i] - alpha_i_old\n",
    "                    delta_alpha_j = self.alpha[j] - alpha_j_old\n",
    "                    self.f += (delta_alpha_i * self.y[i] * self.K[:, i].reshape(-1, 1)) + \\\n",
    "                              (delta_alpha_j * self.y[j] * self.K[:, j].reshape(-1, 1))\n",
    "\n",
    "                    num_changed_alphas += 1\n",
    "                    self.iteration += 1\n",
    "\n",
    "            if X_test is not None and y_test is not None:\n",
    "                y_pred_test = self.predict(X_test)\n",
    "                test_accuracy = self.evaluate_accuracy(y_test, y_pred_test)\n",
    "                self.test_accuracy_history.append(test_accuracy)\n",
    "                self.eval_points.append(self.iteration)\n",
    "\n",
    "            loss = self._compute_loss()\n",
    "            self.loss_history.append(loss)\n",
    "\n",
    "            if num_changed_alphas == 0:\n",
    "                passes += 1\n",
    "            else:\n",
    "                passes = 0\n",
    "\n",
    "    def _select_j(self, i, m):\n",
    "        E_i = self.f[i] - self.y[i]\n",
    "        E_diff = np.abs(self.f.flatten() - E_i.flatten())\n",
    "        E_diff[i] = -1\n",
    "        j = np.argmax(E_diff)\n",
    "        if E_diff[j] == -1:\n",
    "            j = i\n",
    "            while j == i:\n",
    "                j = np.random.randint(0, m)\n",
    "        return j\n",
    "\n",
    "    def _compute_loss(self):\n",
    "        term1 = np.sum(self.alpha)\n",
    "        term2 = 0.5 * np.sum(self.alpha * self.y * (self.K @ self.alpha * self.y))\n",
    "        loss = term1 - term2\n",
    "        return loss.item()\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        K = kernel_function(X, self.X, kernel_type=self.kernel,\n",
    "                            degree=self.degree, gamma=self.gamma)\n",
    "        y_pred = (K @ (self.alpha * self.y)) + self.b\n",
    "        return np.sign(y_pred)\n",
    "\n",
    "    def evaluate_accuracy(self, y_true, y_pred):\n",
    "        y_true = y_true.flatten()\n",
    "        y_pred = y_pred.flatten()\n",
    "        return np.mean(y_true == y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85655b0077ed9e32"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## main"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbe8e57f9efb5047"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Загрузка и предобработка данных:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae8a5967204e3241"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    X_train, X_val, y_train, y_val, test_df = get_processed_data()\n",
    "    print(f'Размер тренировочной выборки: {X_train.shape}')\n",
    "    print(f'Размер валидационной выборки: {X_val.shape}')\n",
    "\n",
    "    X_full = np.vstack((X_train.values, X_val.values))\n",
    "    y_full = np.hstack((y_train.values, y_val.values))\n",
    "    return X_full, y_full"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2192597a5607a90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_full, y_full = load_and_preprocess_data()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c4cb552e14c5c4b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Линейная регрессия"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abf8fc7e106c22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prepare_data_for_regression(X_full, y_full):\n",
    "    y_transformed = transform_labels_lr(y_full).astype(float)\n",
    "    X_with_intercept = add_intercept_lr(X_full).astype(float)\n",
    "    return X_with_intercept, y_transformed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "935a66fa4d68ebd0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def normalize_features(X):\n",
    "    X_features = X[:, 1:]\n",
    "    X_mean = np.mean(X_features, axis=0)\n",
    "    X_std = np.std(X_features, axis=0)\n",
    "    X_std_corrected = np.where(X_std == 0, 1, X_std)\n",
    "    X_features_normalized = (X_features - X_mean) / X_std_corrected\n",
    "    X_normalized = np.hstack((np.ones((X_features_normalized.shape[0], 1)), X_features_normalized))\n",
    "    return X_normalized"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d4078dd9d27f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def linear_regression_with_ridge(X_train, y_train, X_test, y_test):\n",
    "    lambda_values = np.logspace(-4, 4, 30)\n",
    "    best_lambda = None\n",
    "    best_accuracy = 0\n",
    "    accuracies = []\n",
    "\n",
    "    for lambda_reg in lambda_values:\n",
    "        w = ridge_regression(X_train, y_train, lambda_reg)\n",
    "        y_pred = predict_lr(X_test, w)\n",
    "        accuracy = evaluate_accuracy_lr(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f'Lambda: {lambda_reg:.4f}, Accuracy: {accuracy:.4f}')\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_lambda = lambda_reg\n",
    "\n",
    "    print(f'Лучшее значение lambda для гребневой регрессии: {best_lambda}, Accuracy: {best_accuracy:.4f}')\n",
    "\n",
    "    w_best = ridge_regression(X_train, y_train, best_lambda)\n",
    "    y_pred_test = predict_lr(X_test, w_best)\n",
    "    final_accuracy = evaluate_accuracy_lr(y_test, y_pred_test)\n",
    "    print(f'Итоговая точность на тестовой выборке (Линейная регрессия): {final_accuracy:.4f}')\n",
    "\n",
    "    global best_lambda_lr\n",
    "    best_lambda_lr = best_lambda\n",
    "\n",
    "    plt.figure()\n",
    "    plt.semilogx(lambda_values, accuracies, marker='o')\n",
    "    plt.xlabel('Lambda (регуляризация)')\n",
    "    plt.ylabel('Точность')\n",
    "    plt.title('Зависимость точности линейной регрессии от регуляризации')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return w_best, final_accuracy, best_lambda"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92b61da36a7cb355"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_lr, y_lr = prepare_data_for_regression(X_full, y_full)\n",
    "X_lr = normalize_features(X_lr)\n",
    "X_train_lr, X_test_lr, y_train_lr, y_test_lr = split_data(X_lr, y_lr)\n",
    "\n",
    "print(\"=== Линейная регрессия с гребневой регуляризацией ===\")\n",
    "w_lr, final_accuracy_lr, best_lambda_lr = linear_regression_with_ridge(\n",
    "    X_train_lr, y_train_lr, X_test_lr, y_test_lr\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f3a5b759f23b9eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Линейная классификация"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91baa1a839b3596c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Построение графика потерь"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a662ac144e8f3f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_loss_curve(loss_history, title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(len(loss_history)), loss_history, label='Функция потерь')\n",
    "    plt.xlabel('Итерация')\n",
    "    plt.ylabel('Значение функции потерь')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2a9bc56f9312d05"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def linear_classification_with_gd(X_train, y_train, X_test, y_test):\n",
    "    loss_functions = ['mse', 'logistic', 'exponential']\n",
    "    learning_rates = [0.001, 0.005, 0.01]\n",
    "    lambda1_values = [0.0, 0.01, 0.1]\n",
    "    lambda2_values = [0.0, 0.01, 0.1]\n",
    "    n_iterations = 1000\n",
    "\n",
    "    best_params = {}\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for loss in loss_functions:\n",
    "        for lr in learning_rates:\n",
    "            for l1 in lambda1_values:\n",
    "                for l2 in lambda2_values:\n",
    "                    classifier = LinearClassifier(\n",
    "                        loss=loss,\n",
    "                        learning_rate=lr,\n",
    "                        n_iterations=n_iterations,\n",
    "                        lambda1=l1,\n",
    "                        lambda2=l2\n",
    "                    )\n",
    "                    classifier.fit(X_train, y_train, X_test, y_test)\n",
    "                    y_pred = classifier.predict(X_test)\n",
    "                    accuracy = classifier.evaluate_accuracy(y_test, y_pred)\n",
    "                    print(f'Loss: {loss}, LR: {lr}, L1: {l1}, L2: {l2}, Accuracy: {accuracy:.4f}')\n",
    "                    if accuracy > best_accuracy:\n",
    "                        best_accuracy = accuracy\n",
    "                        best_params = {\n",
    "                            'loss': loss,\n",
    "                            'learning_rate': lr,\n",
    "                            'lambda1': l1,\n",
    "                            'lambda2': l2,\n",
    "                            'n_iterations': n_iterations\n",
    "                        }\n",
    "                        best_loss_history = classifier.test_loss_history.copy()\n",
    "\n",
    "    print(f'Лучшие параметры для линейной классификации: {best_params}, Accuracy: {best_accuracy:.4f}')\n",
    "\n",
    "    global best_params_lc\n",
    "    best_params_lc = best_params\n",
    "\n",
    "    classifier_best = LinearClassifier(\n",
    "        loss=best_params['loss'],\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        n_iterations=best_params['n_iterations'],\n",
    "        lambda1=best_params['lambda1'],\n",
    "        lambda2=best_params['lambda2']\n",
    "    )\n",
    "    classifier_best.fit(X_train, y_train, X_test, y_test)\n",
    "    y_pred_test = classifier_best.predict(X_test)\n",
    "    final_accuracy = classifier_best.evaluate_accuracy(y_test, y_pred_test)\n",
    "    print(f'Итоговая точность на тестовой выборке (Линейная классификация): {final_accuracy:.4f}')\n",
    "\n",
    "    plot_loss_curve(classifier_best.test_loss_history, 'Кривая функции потерь на тестовом множестве (Линейная классификация)')\n",
    "\n",
    "    return classifier_best, final_accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7d3993f3e26eb98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"=== Линейная классификация на основе градиентного спуска ===\")\n",
    "classifier_lc, final_accuracy_lc = linear_classification_with_gd(\n",
    "    X_train_lr, y_train_lr, X_test_lr, y_test_lr\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffdf412d6c15a4e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### svm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92165b11286a995b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def svm_with_smo(X_train, y_train, X_test, y_test):\n",
    "    kernels = ['linear', 'polynomial', 'rbf']\n",
    "    C_values = [0.01, 0.1, 1]\n",
    "    tol_values = [1e-3, 1e-4]\n",
    "    max_passes_values = [5, 10, 50, 100]\n",
    "    degree_values = [2, 3, 4]\n",
    "    gamma_values = [0.1, 1.0]\n",
    "\n",
    "    best_params = {}\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for kernel in kernels:\n",
    "        for C in C_values:\n",
    "            for tol in tol_values:\n",
    "                for max_passes in max_passes_values:\n",
    "                    if kernel == 'polynomial':\n",
    "                        for degree in degree_values:\n",
    "                            svm = SVM_SMO(\n",
    "                                kernel=kernel,\n",
    "                                C=C,\n",
    "                                tol=tol,\n",
    "                                max_passes=max_passes,\n",
    "                                degree=degree\n",
    "                            )\n",
    "                            svm.fit(X_train, y_train, X_test, y_test)\n",
    "                            y_pred = svm.predict(X_test)\n",
    "                            accuracy = svm.evaluate_accuracy(y_test, y_pred)\n",
    "                            print(\n",
    "                                f'Kernel: {kernel}, C: {C}, tol: {tol}, '\n",
    "                                f'max_passes: {max_passes}, degree: {degree}, Accuracy: {accuracy:.4f}')\n",
    "                            if accuracy > best_accuracy:\n",
    "                                best_accuracy = accuracy\n",
    "                                best_params = {\n",
    "                                    'kernel': kernel,\n",
    "                                    'C': C,\n",
    "                                    'tol': tol,\n",
    "                                    'max_passes': max_passes,\n",
    "                                    'degree': degree\n",
    "                                }\n",
    "                    elif kernel == 'rbf':\n",
    "                        for gamma in gamma_values:\n",
    "                            svm = SVM_SMO(\n",
    "                                kernel=kernel,\n",
    "                                C=C,\n",
    "                                tol=tol,\n",
    "                                max_passes=max_passes,\n",
    "                                gamma=gamma\n",
    "                            )\n",
    "                            svm.fit(X_train, y_train, X_test, y_test)\n",
    "                            y_pred = svm.predict(X_test)\n",
    "                            accuracy = svm.evaluate_accuracy(y_test, y_pred)\n",
    "                            print(\n",
    "                                f'Kernel: {kernel}, C: {C}, tol: {tol}, '\n",
    "                                f'max_passes: {max_passes}, gamma: {gamma}, Accuracy: {accuracy:.4f}')\n",
    "                            if accuracy > best_accuracy:\n",
    "                                best_accuracy = accuracy\n",
    "                                best_params = {\n",
    "                                    'kernel': kernel,\n",
    "                                    'C': C,\n",
    "                                    'tol': tol,\n",
    "                                    'max_passes': max_passes,\n",
    "                                    'gamma': gamma\n",
    "                                }\n",
    "                    else:\n",
    "                        svm = SVM_SMO(\n",
    "                            kernel=kernel,\n",
    "                            C=C,\n",
    "                            tol=tol,\n",
    "                            max_passes=max_passes\n",
    "                        )\n",
    "                        svm.fit(X_train, y_train, X_test, y_test)\n",
    "                        y_pred = svm.predict(X_test)\n",
    "                        accuracy = svm.evaluate_accuracy(y_test, y_pred)\n",
    "                        print(\n",
    "                            f'Kernel: {kernel}, C: {C}, tol: {tol}, '\n",
    "                            f'max_passes: {max_passes}, Accuracy: {accuracy:.4f}')\n",
    "                        if accuracy > best_accuracy:\n",
    "                            best_accuracy = accuracy\n",
    "                            best_params = {\n",
    "                                'kernel': kernel,\n",
    "                                'C': C,\n",
    "                                'tol': tol,\n",
    "                                'max_passes': max_passes\n",
    "                            }\n",
    "\n",
    "    print(f'Лучшие параметры для SVM: {best_params}, Accuracy: {best_accuracy:.4f}')\n",
    "\n",
    "    global best_params_svm\n",
    "    best_params_svm = best_params\n",
    "\n",
    "    svm_best = SVM_SMO(\n",
    "        kernel=best_params['kernel'],\n",
    "        C=best_params['C'],\n",
    "        tol=best_params['tol'],\n",
    "        max_passes=best_params['max_passes'],\n",
    "        degree=best_params.get('degree', 3),\n",
    "        gamma=best_params.get('gamma', None)\n",
    "    )\n",
    "    svm_best.fit(X_train, y_train, X_test, y_test)\n",
    "    y_pred_test = svm_best.predict(X_test)\n",
    "    final_accuracy = svm_best.evaluate_accuracy(y_test, y_pred_test)\n",
    "    print(f'Итоговая точность на тестовой выборке (SVM): {final_accuracy:.4f}')\n",
    "\n",
    "    plot_loss_curve(svm_best.loss_history, 'Кривая функции потерь на тестовом множестве (SVM)')\n",
    "\n",
    "    return svm_best, final_accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c95ecfafc9ed4e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"=== Метод опорных векторов (SVM) с SMO ===\")\n",
    "svm_model, final_accuracy_svm = svm_with_smo(\n",
    "    X_train_lr[:, 1:], y_train_lr.flatten(), X_test_lr[:, 1:], y_test_lr.flatten()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "960c5dace5b78212"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Построение графиков"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90a1fe765161dbd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def collect_learning_curves(model_class, X_full, y_full, n_runs=50):\n",
    "    test_accuracies = []\n",
    "    eval_points_list = []\n",
    "\n",
    "    for run in range(n_runs):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_full, y_full, test_size=0.5, stratify=y_full, random_state=run)\n",
    "\n",
    "        if model_class == 'linear_classifier':\n",
    "            classifier = LinearClassifier(\n",
    "                loss=best_params_lc['loss'],\n",
    "                learning_rate=best_params_lc['learning_rate'],\n",
    "                n_iterations=best_params_lc['n_iterations'],\n",
    "                lambda1=best_params_lc['lambda1'],\n",
    "                lambda2=best_params_lc['lambda2'],\n",
    "            )\n",
    "            classifier.fit(X_train, y_train, X_test, y_test)\n",
    "            test_accuracies.append(classifier.test_accuracy_history)\n",
    "            eval_points_list.append(np.arange(0, best_params_lc['n_iterations']))\n",
    "        elif model_class == 'svm':\n",
    "            svm = SVM_SMO(\n",
    "                kernel=best_params_svm['kernel'],\n",
    "                C=best_params_svm['C'],\n",
    "                tol=best_params_svm['tol'],\n",
    "                max_passes=best_params_svm['max_passes'],\n",
    "                degree=best_params_svm.get('degree', 3),\n",
    "                gamma=best_params_svm.get('gamma', None)\n",
    "            )\n",
    "            svm.fit(X_train, y_train, X_test, y_test)\n",
    "            test_accuracies.append(svm.test_accuracy_history)\n",
    "            eval_points_list.append(svm.eval_points)\n",
    "\n",
    "    max_length = max(len(acc) for acc in test_accuracies)\n",
    "    test_accuracies_padded = [np.pad(acc, (0, max_length - len(acc)), 'edge') for acc in test_accuracies]\n",
    "    eval_points_padded = [np.pad(points, (0, max_length - len(points)), 'edge') for points in eval_points_list]\n",
    "    test_accuracies = np.array(test_accuracies_padded)\n",
    "    eval_points = np.array(eval_points_padded).mean(axis=0)\n",
    "    return test_accuracies, eval_points"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b55846a389357648"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_linear_regression_accuracy(X_train_lr, y_train_lr, X_test_lr, y_test_lr):\n",
    "    w = ridge_regression(X_train_lr, y_train_lr, best_lambda_lr)\n",
    "    y_pred_test = predict_lr(X_test_lr, w)\n",
    "    accuracy = evaluate_accuracy_lr(y_test_lr, y_pred_test)\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "549fe879a2084cb2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_learning_curve_with_confidence(test_accuracies, eval_points, title, lr_accuracy):\n",
    "    mean_accuracy = np.mean(test_accuracies, axis=0)\n",
    "    std_accuracy = np.std(test_accuracies, axis=0)\n",
    "    n_runs = test_accuracies.shape[0]\n",
    "    standard_error = std_accuracy / np.sqrt(n_runs)\n",
    "    confidence_interval = 1.96 * standard_error\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(eval_points, mean_accuracy, label='Средняя точность на тестовом множестве')\n",
    "    plt.fill_between(eval_points, mean_accuracy - confidence_interval, mean_accuracy + confidence_interval, alpha=0.2)\n",
    "    plt.axhline(y=lr_accuracy, color='r', linestyle='--', label='Линейная регрессия')\n",
    "    plt.xlabel('Итерация')\n",
    "    plt.ylabel('Точность на тестовом множестве')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b3243363f3f1a5c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_runs = 50\n",
    "test_accuracies_lc, eval_points_lc = collect_learning_curves(\n",
    "    'linear_classifier', X_lr, y_lr, n_runs\n",
    ")\n",
    "test_accuracies_svm, eval_points_svm = collect_learning_curves(\n",
    "    'svm', X_lr[:, 1:], y_lr, n_runs\n",
    ")\n",
    "\n",
    "lr_accuracy = get_linear_regression_accuracy(\n",
    "    X_train_lr, y_train_lr, X_test_lr, y_test_lr\n",
    ")\n",
    "\n",
    "plot_learning_curve_with_confidence(\n",
    "    test_accuracies_lc,\n",
    "    eval_points_lc,\n",
    "    'Кривая обучения для линейной классификации',\n",
    "    lr_accuracy\n",
    ")\n",
    "\n",
    "plot_learning_curve_with_confidence(\n",
    "    test_accuracies_svm,\n",
    "    eval_points_svm,\n",
    "    'Кривая обучения для SVM',\n",
    "    lr_accuracy\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "979aca9626edf346"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
